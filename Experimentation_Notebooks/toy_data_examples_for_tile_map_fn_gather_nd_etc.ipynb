{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "[[[3 2 1]\n",
      "  [7 8 9]\n",
      "  [1 1 1]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [1 1 1]\n",
      "  [1 1 1]]\n",
      "\n",
      " [[2 2 2]\n",
      "  [3 3 3]\n",
      "  [1 1 1]]\n",
      "\n",
      " [[4 4 4]\n",
      "  [5 5 5]\n",
      "  [1 1 1]]]\n",
      "a.shape=(4, 3, 3)\n",
      "y=\n",
      "[[[ -5  -5  -5  -5]\n",
      "  [ -5  -5  -5  -5]\n",
      "  [ -5  -5  -5  -5]]\n",
      "\n",
      " [[ -7  -7  -7  -7]\n",
      "  [ -7  -7  -7  -7]\n",
      "  [ -7  -7  -7  -7]]\n",
      "\n",
      " [[ -9  -9  -9  -9]\n",
      "  [ -9  -9  -9  -9]\n",
      "  [ -9  -9  -9  -9]]\n",
      "\n",
      " [[-11 -11 -11  -9]\n",
      "  [-11 -11 -11  -9]\n",
      "  [-11 -11 -11  -9]]]\n",
      "z=\n",
      "[[[  3   2   1  -5  -5  -5  -5]\n",
      "  [  7   8   9  -5  -5  -5  -5]\n",
      "  [  1   1   1  -5  -5  -5  -5]]\n",
      "\n",
      " [[  0   0   0  -7  -7  -7  -7]\n",
      "  [  1   1   1  -7  -7  -7  -7]\n",
      "  [  1   1   1  -7  -7  -7  -7]]\n",
      "\n",
      " [[  2   2   2  -9  -9  -9  -9]\n",
      "  [  3   3   3  -9  -9  -9  -9]\n",
      "  [  1   1   1  -9  -9  -9  -9]]\n",
      "\n",
      " [[  4   4   4 -11 -11 -11  -9]\n",
      "  [  5   5   5 -11 -11 -11  -9]\n",
      "  [  1   1   1 -11 -11 -11  -9]]]\n"
     ]
    }
   ],
   "source": [
    "# example usage of tf.tile. \n",
    "# Aim: Our tensor a is 3 dimensional in its last dimension.  We call its first dimension the batch dimension.\n",
    "# For each batch, we want to append a constant vector to all vectors of that batch (go from a to z in output below)\n",
    "\n",
    "a=tf.constant([[[3,2,1],[7,8,9],[1,1,1]],\n",
    "               [[0,0,0],[1,1,1],[1,1,1]], \n",
    "               [[2,2,2],[3,3,3],[1,1,1]], \n",
    "               [[4,4,4],[5,5,5],[1,1,1]]])\n",
    "\n",
    "# 4 vectors to append, for 4 different batches\n",
    "y=tf.constant([[-5,-5,-5,-5],[-7,-7,-7,-7],[-9,-9,-9,-9],[-11,-11,-11,-9]])\n",
    "# make copies of those vectors with tf.tile\n",
    "y=tf.tile(y,[1,tf.shape(a)[1]])\n",
    "# reshape them, so that they can be appended\n",
    "y=tf.reshape(y,[tf.shape(a)[0],tf.shape(a)[1],-1])\n",
    "# append\n",
    "z=tf.concat([a,y],axis=2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(\"a=\")\n",
    "    print(sess.run(a))\n",
    "    print(\"a.shape={}\".format(a.shape))\n",
    "    print(\"y=\")\n",
    "    print(sess.run(y))\n",
    "    print(\"z=\")\n",
    "    print(sess.run(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Tensor\n",
      "[[ 1.  2.  3.]\n",
      " [ 4.  5.  6.]]\n",
      "---Mask\n",
      "[[ True False  True]\n",
      " [ True  True False]]\n",
      "---tensor*tf.cast(mask,dtype=tf.float32)\n",
      "[[ 1.  0.  3.]\n",
      " [ 4.  5.  0.]]\n",
      "---tf.boolean_mask(tensor,mask)\n",
      "[ 1.  3.  4.  5.]\n"
     ]
    }
   ],
   "source": [
    "# example usage of a mask tensor\n",
    "tensor = tf.constant(np.array([[1, 2, 3],[4, 5, 6]]), dtype=tf.float32)\n",
    "mask = tf.constant(np.array([[True, False, True],[True,True,False]]))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(\"---Tensor\")\n",
    "    print(sess.run(tensor))\n",
    "    print(\"---Mask\")\n",
    "    print(sess.run(mask))\n",
    "    print(\"---tensor*tf.cast(mask,dtype=tf.float32)\")\n",
    "    print(sess.run(tensor*tf.cast(mask,dtype=tf.float32)))\n",
    "    print(\"---tf.boolean_mask(tensor,mask)\")\n",
    "    print(sess.run(tf.boolean_mask(tensor,mask)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=Tensor(\"Const_15:0\", shape=(2, 3, 4), dtype=int32)\n",
      "b=Tensor(\"Reshape_7:0\", shape=(?, 1, ?), dtype=int32)\n",
      "a\n",
      "[[[ 1  0  0  0]\n",
      "  [ 2  0  0  0]\n",
      "  [ 3  0  0  0]]\n",
      "\n",
      " [[-1  0  0  0]\n",
      "  [-2  0  0  0]\n",
      "  [-3  0  0  0]]]\n",
      "b\n",
      "[[[7 7 7 7]]\n",
      "\n",
      " [[7 7 7 7]]]\n",
      "z\n",
      "[[[ 1  0  0  0]\n",
      "  [ 2  0  0  0]\n",
      "  [ 3  0  0  0]\n",
      "  [ 7  7  7  7]]\n",
      "\n",
      " [[-1  0  0  0]\n",
      "  [-2  0  0  0]\n",
      "  [-3  0  0  0]\n",
      "  [ 7  7  7  7]]]\n"
     ]
    }
   ],
   "source": [
    "# Using our knowledge about tf tile to append a sentinel vector (go from a to z in output below)\n",
    "a=tf.constant([[[1,0,0,0],[2,0,0,0],[3,0,0,0]],[[-1,0,0,0],[-2,0,0,0],[-3,0,0,0]]])\n",
    "b=tf.constant([7,7,7,7])\n",
    "b=tf.tile(b,tf.shape(a)[0:1])\n",
    "b=tf.reshape(b,(-1,1,tf.shape(a)[2]))\n",
    "z=tf.concat([a,b],axis=1)\n",
    "print(\"a={}\".format(a))\n",
    "print(\"b={}\".format(b))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(\"a\")\n",
    "    print(sess.run(a))\n",
    "    print(\"b\")\n",
    "    print(sess.run(b))\n",
    "    print(\"z\")\n",
    "    print(sess.run(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?,)\n",
      "(2, 4)\n",
      "z\n",
      "[[ 1.  1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "#Another example needed for sentinel implementation\n",
    "a=tf.constant([[1,1,0,0],[1,0,0,0]],dtype=tf.float32)\n",
    "b=tf.constant([0],dtype=tf.float32)\n",
    "b=tf.tile(b,[tf.shape(a)[0]])\n",
    "print(b.shape)\n",
    "print(a.shape)\n",
    "b=tf.reshape(b,(tf.shape(a)[0],1))\n",
    "z=tf.concat([a,b],axis=1)\n",
    "with tf.Session() as sess:\n",
    "    print(\"z\")\n",
    "    print(sess.run(z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# In the code of the DCN_model, adding a sentinel could look like this (not yet implemented)\n",
    "#logging.info(\"q_outputs={}\".format(q_outputs))\n",
    "#q_sentinel = tf.get_variable(\"q_sentinel\", (rnn_size,), initializer=tf.contrib.layers.xavier_initializer())\n",
    "#q_sentinel = tf.tile(q_sentinel, tf.shape(q_outputs)[0:1])\n",
    "#q_sentinel = tf.reshape(q_sentinel, (-1, 1, tf.shape(q_outputs)[2]))\n",
    "#Qprime = tf.concat([q_outputs, q_sentinel], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.  0.  2.  0.]\n",
      "  [ 2.  0.  3.  0.]\n",
      "  [ 3.  0.  4.  0.]]\n",
      "\n",
      " [[ 5.  0.  6.  0.]\n",
      "  [ 6.  0.  7.  0.]\n",
      "  [ 7.  0.  8.  0.]]]\n",
      "[[[  2.24515244e-01   8.25945437e-02   6.10295713e-01   8.25945437e-02]\n",
      "  [  2.50692427e-01   3.39275263e-02   6.81452632e-01   3.39275263e-02]\n",
      "  [  2.61927158e-01   1.30405845e-02   7.11991787e-01   1.30405845e-02]]\n",
      "\n",
      " [[  2.67970264e-01   1.80556939e-03   7.28418648e-01   1.80556939e-03]\n",
      "  [  2.68583328e-01   6.65751519e-04   7.30085194e-01   6.65751519e-04]\n",
      "  [  2.68809587e-01   2.45122617e-04   7.30700195e-01   2.45122617e-04]]]\n",
      "[[[ 0.09003057  0.24472848  0.66524094]\n",
      "  [ 0.33333334  0.33333334  0.33333334]\n",
      "  [ 0.09003057  0.24472848  0.66524094]\n",
      "  [ 0.33333334  0.33333334  0.33333334]]\n",
      "\n",
      " [[ 0.09003057  0.24472848  0.66524094]\n",
      "  [ 0.33333334  0.33333334  0.33333334]\n",
      "  [ 0.09003057  0.24472848  0.66524094]\n",
      "  [ 0.33333334  0.33333334  0.33333334]]]\n"
     ]
    }
   ],
   "source": [
    "# example usage of softmax\n",
    "a=tf.constant([[[1,0,2,0],[2,0,3,0],[3,0,4,0]],[[5,0,6,0],[6,0,7,0],[7,0,8,0]]],dtype='float32')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(a))\n",
    "    print(sess.run(tf.nn.softmax(a)))\n",
    "    print(sess.run(tf.nn.softmax(tf.transpose(a,[0,2,1]))))\n",
    "#=>softmax is row wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------logits\n",
      "[[[ 10.  10.  20.  20.]\n",
      "  [ 11.  10.  10.  30.]\n",
      "  [ 12.  10.  10.  20.]\n",
      "  [ 13.  10.  10.  20.]]\n",
      "\n",
      " [[ 14.  11.  21.  31.]\n",
      "  [ 15.  11.  11.  21.]\n",
      "  [ 16.  11.  11.  21.]\n",
      "  [ 17.  11.  11.  21.]]]\n",
      "------------result\n",
      "[[ 11.  10.  10.  30.]\n",
      " [ 17.  11.  11.  21.]\n",
      " [ 15.  11.  11.  21.]]\n"
     ]
    }
   ],
   "source": [
    "# gather_nd example\n",
    "logits = tf.constant([[[10.0, 10.0, 20.0, 20.0],\n",
    "                      [11.0, 10.0, 10.0, 30.0],\n",
    "                      [12.0, 10.0, 10.0, 20.0],\n",
    "                      [13.0, 10.0, 10.0, 20.0]],\n",
    "                     [[14.0, 11.0, 21.0, 31.0],\n",
    "                      [15.0, 11.0, 11.0, 21.0],\n",
    "                      [16.0, 11.0, 11.0, 21.0],\n",
    "                      [17.0, 11.0, 11.0, 21.0]]])\n",
    "\n",
    "# pick vector 1 in batch 0, then vec 3 in batch 1 then vec 1 in batch 1\n",
    "indices = tf.constant([[0,1],[1,3],[1,1]]) \n",
    "\n",
    "result = tf.gather_nd(logits, indices)\n",
    "with tf.Session() as sess:\n",
    "    print(\"------------logits\")\n",
    "    print(sess.run(logits))\n",
    "    print(\"------------result\")\n",
    "    print(sess.run(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[-1  2  5]\n"
     ]
    }
   ],
   "source": [
    "#tf range is simple :)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.range(0,2,1))) #start, stop, step\n",
    "    print(sess.run(tf.range(-1,7,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_10:0\", shape=(3,), dtype=int32)\n",
      "Tensor(\"Const_9:0\", shape=(3, 4, 4), dtype=float32)\n",
      "----------logits\n",
      "[[[ 10.  10.  20.  20.]\n",
      "  [ 11.  10.  10.  30.]\n",
      "  [ 12.  10.  10.  20.]\n",
      "  [ 13.  10.  10.  20.]]\n",
      "\n",
      " [[ 14.  11.  21.  31.]\n",
      "  [ 15.  11.  11.  21.]\n",
      "  [ 16.  11.  11.  21.]\n",
      "  [ 17.  11.  11.  21.]]\n",
      "\n",
      " [[ -1.  11.  21.  31.]\n",
      "  [ -2.  11.  11.  21.]\n",
      "  [ -3.  11.  11.  21.]\n",
      "  [ -4.  11.  11.  21.]]]\n",
      "----------concat idx and pick\n",
      "[0 1 2 0 3 2]\n",
      "----------stack idx and pick to obtain n_idx\n",
      "[[0 0]\n",
      " [1 3]\n",
      " [2 2]]\n",
      "----------access logits via the index array n_idx\n",
      "[[ 10.  10.  20.  20.]\n",
      " [ 17.  11.  11.  21.]\n",
      " [ -3.  11.  11.  21.]]\n"
     ]
    }
   ],
   "source": [
    "# Example code for picking us and ue from U using tf.gather_nd() (see DCN_model.py)\n",
    "logits = tf.constant([[[10.0, 10.0, 20.0, 20.0],\n",
    "                      [11.0, 10.0, 10.0, 30.0],\n",
    "                      [12.0, 10.0, 10.0, 20.0],\n",
    "                      [13.0, 10.0, 10.0, 20.0]],\n",
    "                     [[14.0, 11.0, 21.0, 31.0],\n",
    "                      [15.0, 11.0, 11.0, 21.0],\n",
    "                      [16.0, 11.0, 11.0, 21.0],\n",
    "                      [17.0, 11.0, 11.0, 21.0]],\n",
    "                     [[-1, 11.0, 21.0, 31.0],\n",
    "                      [-2, 11.0, 11.0, 21.0],\n",
    "                      [-3, 11.0, 11.0, 21.0],\n",
    "                      [-4, 11.0, 11.0, 21.0]]])\n",
    "\n",
    "# in theses 3 batches of logits, I want to pick vec 0 in batch 0, vec 3 in batch 1, vec 2 in batch 2\n",
    "pick = tf.constant([0,3,2],dtype='int32') \n",
    "print(pick)\n",
    "idx = tf.range(0,tf.shape(pick)[0],1)\n",
    "n_idx = tf.stack([idx,pick],axis=1)\n",
    "\n",
    "print(logits)\n",
    "\n",
    "result = tf.gather_nd(logits, n_idx)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(10*\"-\"+\"logits\")\n",
    "    print(sess.run(logits))\n",
    "    print(10*\"-\"+\"concat idx and pick\")\n",
    "    print(sess.run(tf.concat([idx,pick],axis=0)))\n",
    "    print(10*\"-\"+\"stack idx and pick to obtain n_idx\")\n",
    "    print(sess.run(n_idx))\n",
    "    print(10*\"-\"+\"access logits via the index array n_idx\")\n",
    "    print(sess.run(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_11:0\", shape=(2, 3, 4), dtype=float32)\n",
      "Tensor(\"transpose_1:0\", shape=(3, 2, 4), dtype=float32)\n",
      "(3, 2)\n",
      "----------U\n",
      "[[[ 1.  4.  3.  0.]\n",
      "  [ 2.  0. -1.  0.]\n",
      "  [ 7.  0.  5.  0.]]\n",
      "\n",
      " [[-1.  0.  0.  0.]\n",
      "  [-2.  0.  0.  0.]\n",
      "  [-3.  5.  5.  5.]]]\n",
      "----------U_transpose\n",
      "[[[ 1.  4.  3.  0.]\n",
      "  [-1.  0.  0.  0.]]\n",
      "\n",
      " [[ 2.  0. -1.  0.]\n",
      "  [-2.  0.  0.  0.]]\n",
      "\n",
      " [[ 7.  0.  5.  0.]\n",
      "  [-3.  5.  5.  5.]]]\n",
      "----------Utilde\n",
      "[[  5.  -2.]\n",
      " [  3.  -4.]\n",
      " [ 19.  -1.]]\n",
      "----------tf.reshape(Utilde,[2,3])) fails to do the right thing!\n",
      "[[  5.  -2.   3.]\n",
      " [ -4.  19.  -1.]]\n",
      "----------tf.transpose(Utilde,[1,0])) gives the desired result\n",
      "[[  5.   3.  19.]\n",
      " [ -2.  -4.  -1.]]\n",
      "----------\n",
      "[2 2]\n"
     ]
    }
   ],
   "source": [
    "# map_fn example. Pretty near to what is needed for the HMN decoder\n",
    "# Aim in this example: Each vector in U (along last dimension), should be mapped to its dot product with [2,0,1,0]\n",
    "# but assume that we have to transpose U first and have to work with U_transpose=tf.transpose(U,[1,0,2])\n",
    "U=tf.constant([[[1,4,3,0],[2,0,-1,0],[7,0,5,0]],[[-1,0,0,0],[-2,0,0,0],[-3,5,5,5]]], dtype='float32')\n",
    "U_transpose=tf.transpose(U,[1,0,2])\n",
    "print(U)\n",
    "print(U_transpose)\n",
    "proj = tf.constant([2,0,1,0],dtype='float32')\n",
    "def funci(u_t,projo):\n",
    "    return tf.reduce_sum(tf.multiply(u_t, projo),axis=1)\n",
    "#fn = lambda u_t: tf.multiply(u_t, proj)\n",
    "Utilde=tf.map_fn(lambda u_t: funci(u_t,proj), U_transpose, dtype=tf.float32)\n",
    "print(Utilde.shape)\n",
    "alpha = tf.transpose(Utilde,[1,0])\n",
    "with tf.Session() as sess:\n",
    "    print(10*\"-\"+\"U\")\n",
    "    print(sess.run(U))\n",
    "    print(10*\"-\"+\"U_transpose\")\n",
    "    print(sess.run(U_transpose))\n",
    "    print(10*\"-\"+\"Utilde\")\n",
    "    print(sess.run(Utilde))\n",
    "    print(\"-\"*10+\"tf.reshape(Utilde,[2,3])) fails to do the right thing!\")\n",
    "    print(sess.run(tf.reshape(Utilde,[2,3])))\n",
    "    print(\"-\"*10+\"tf.transpose(Utilde,[1,0])) gives the desired result\")\n",
    "    print(sess.run(tf.transpose(Utilde,[1,0])))\n",
    "    print(\"-\"*10)\n",
    "    print(sess.run(tf.argmax(alpha,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [7 8 9]]\n",
      "[3 9]\n"
     ]
    }
   ],
   "source": [
    "# example usage of reduce_max, necessary for the HMN decoder\n",
    "U=tf.constant([[1,2,3],[7,8,9]])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(U))\n",
    "    print(sess.run(tf.reduce_max(U,axis=1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
